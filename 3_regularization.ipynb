{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kR-4eNdK6lYS"
   },
   "source": [
    "Deep Learning\n",
    "=============\n",
    "\n",
    "Assignment 3\n",
    "------------\n",
    "\n",
    "Previously in `2_fullyconnected.ipynb`, you trained a logistic regression and a neural network model.\n",
    "\n",
    "The goal of this assignment is to explore regularization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "JLpLa8Jt7Vu4"
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1HrCK6e17WzV"
   },
   "source": [
    "First reload the data we generated in `1_notmnist.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11777,
     "status": "ok",
     "timestamp": 1449849322348,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "y3-cj1bpmuxc",
    "outputId": "e03576f1-ebbe-4838-c388-f1777bcc9873"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28) (200000,)\n",
      "Validation set (10000, 28, 28) (10000,)\n",
      "Test set (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset = save['train_dataset']\n",
    "  train_labels = save['train_labels']\n",
    "  valid_dataset = save['valid_dataset']\n",
    "  valid_labels = save['valid_labels']\n",
    "  test_dataset = save['test_dataset']\n",
    "  test_labels = save['test_labels']\n",
    "  del save  # hint to help gc free up memory\n",
    "  print('Training set', train_dataset.shape, train_labels.shape)\n",
    "  print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "  print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7aHrm6nGDMB"
   },
   "source": [
    "Reformat into a shape that's more adapted to the models we're going to train:\n",
    "- data as a flat matrix,\n",
    "- labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11728,
     "status": "ok",
     "timestamp": 1449849322356,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "IRSyYiIIGIzS",
    "outputId": "3f8996ee-3574-4f44-c953-5c8a04636582"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 784) (200000, 10)\n",
      "Validation set (10000, 784) (10000, 10)\n",
      "Test set (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)\n",
    "  # Map 1 to [0.0, 1.0, 0.0 ...], 2 to [0.0, 0.0, 1.0 ...]\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "RajPLaL_ZW6w"
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sgLbUAQ1CW-1"
   },
   "source": [
    "---\n",
    "Problem 1\n",
    "---------\n",
    "\n",
    "Introduce and tune L2 regularization for both logistic and neural network models. Remember that L2 amounts to adding a penalty on the norm of the weights to the loss. In TensorFlow, you can compute the L2 loss for a tensor `t` using `nn.l2_loss(t)`. The right amount of regularization should improve your validation / test accuracy.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using L2 Regularization for Logistic Model\n",
      "Tensorflow Graph created\n",
      "Initialized\n",
      "Minibatch loss at step 0: 18.624365\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 8.4%\n",
      "Minibatch loss at step 500: 2.362528\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 77.3%\n",
      "Minibatch loss at step 1000: 1.798701\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 79.3%\n",
      "Minibatch loss at step 1500: 0.959931\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 2000: 0.810217\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 2500: 0.854296\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 3000: 0.761275\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 82.0%\n",
      "Test accuracy: 88.8%\n"
     ]
    }
   ],
   "source": [
    "print('Using L2 Regularization for Logistic Model')\n",
    "batch_size = 128\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    tf_l2_feature = tf.placeholder(tf.float32)\n",
    "\n",
    "    # Variables.\n",
    "    weights = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    # Training computation.\n",
    "    logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "    loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits)) + tf_l2_feature * tf.nn.l2_loss(weights)\n",
    "\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(\n",
    "    tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)\n",
    "\n",
    "print('Tensorflow Graph created')\n",
    "\n",
    "num_steps = 3001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, tf_l2_feature: 1e-3}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "            print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "            print(\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tunning the L2 Regularization constant\n",
      "L2 Regularization constant of 0.000100 performed with 86.55% accuracy\n",
      "L2 Regularization constant of 0.000126 performed with 87.24% accuracy\n",
      "L2 Regularization constant of 0.000158 performed with 87.00% accuracy\n",
      "L2 Regularization constant of 0.000200 performed with 87.69% accuracy\n",
      "L2 Regularization constant of 0.000251 performed with 87.57% accuracy\n",
      "L2 Regularization constant of 0.000316 performed with 87.81% accuracy\n",
      "L2 Regularization constant of 0.000398 performed with 88.12% accuracy\n",
      "L2 Regularization constant of 0.000501 performed with 88.11% accuracy\n",
      "L2 Regularization constant of 0.000631 performed with 88.56% accuracy\n",
      "L2 Regularization constant of 0.000794 performed with 88.87% accuracy\n",
      "L2 Regularization constant of 0.001000 performed with 89.06% accuracy\n",
      "L2 Regularization constant of 0.001259 performed with 88.95% accuracy\n",
      "L2 Regularization constant of 0.001585 performed with 89.01% accuracy\n",
      "L2 Regularization constant of 0.001995 performed with 89.11% accuracy\n",
      "L2 Regularization constant of 0.002512 performed with 89.09% accuracy\n",
      "L2 Regularization constant of 0.003162 performed with 89.12% accuracy\n",
      "L2 Regularization constant of 0.003981 performed with 89.02% accuracy\n",
      "L2 Regularization constant of 0.005012 performed with 88.98% accuracy\n",
      "L2 Regularization constant of 0.006310 performed with 88.86% accuracy\n",
      "L2 Regularization constant of 0.007943 performed with 88.70% accuracy\n"
     ]
    }
   ],
   "source": [
    "print('Tunning the L2 Regularization constant')\n",
    "\n",
    "num_steps = 3001\n",
    "l2_constant_values = [pow(10, i) for i in np.arange(-4, -2, 0.1)]\n",
    "accuracy_values = []\n",
    "max_accuracy, best_l2_constant = 0, 0\n",
    "\n",
    "for l2_constant in l2_constant_values:\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        tf.global_variables_initializer().run()\n",
    "        for step in range(num_steps):\n",
    "            # Pick an offset within the training data, which has been randomized.\n",
    "            # Note: we could use better randomization across epochs.\n",
    "            offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "            # Generate a minibatch.\n",
    "            batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "            batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "            # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "            # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "            # and the value is the numpy array to feed to it.\n",
    "            feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, tf_l2_feature: l2_constant}\n",
    "            _, l, predictions = session.run(\n",
    "              [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        test_accuracy = accuracy(test_prediction.eval(), test_labels)\n",
    "        if test_accuracy == max(max_accuracy, test_accuracy):\n",
    "            max_accuracy = test_accuracy\n",
    "            best_l2_constant = l2_constant\n",
    "        accuracy_values.append(test_accuracy)\n",
    "        print('L2 Regularization constant of %f performed with %.2f%% accuracy' % (l2_constant, accuracy_values[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot the L2 Regularization loss for our Test\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEMCAYAAAAoB2Y1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b70e890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum accuracy is 89.12% with L2 Regularization constant of 0.003162\n"
     ]
    }
   ],
   "source": [
    "print('Plot the L2 Regularization loss for our Test')\n",
    "plt.semilogx(l2_constant_values, accuracy_values)\n",
    "plt.grid(True)\n",
    "plt.title('Accuracy against L2 regularization (Logistic Regression)')\n",
    "plt.show()\n",
    "print('Maximum accuracy is %.2f%% with L2 Regularization constant of %f' % (max_accuracy, best_l2_constant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using L2 Regularization for Neural Network Model (1 Layer):\n",
      "Tensorflow Graph created\n",
      "Initialized\n",
      "Minibatch loss at step 0: 657.511658\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 30.7%\n",
      "Minibatch loss at step 500: 198.994888\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 1000: 116.365997\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 1500: 68.800476\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 83.2%\n",
      "Minibatch loss at step 2000: 41.376598\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 84.6%\n",
      "Minibatch loss at step 2500: 25.256895\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 85.9%\n",
      "Minibatch loss at step 3000: 15.535670\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 86.5%\n",
      "Test accuracy: 93.1%\n"
     ]
    }
   ],
   "source": [
    "print('Using L2 Regularization for Neural Network Model (1 Layer):')\n",
    "batch_size = 128\n",
    "num_hidden_nodes = 1024\n",
    "\n",
    "# Buildig the Network\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    tf_l2_feature = tf.placeholder(tf.float32)\n",
    "\n",
    "    # Variables.\n",
    "    layer1_weights = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, num_hidden_nodes]))\n",
    "    layer1_biases = tf.Variable(tf.zeros([num_hidden_nodes]))\n",
    "    layer2_weights = tf.Variable(\n",
    "    tf.truncated_normal([num_hidden_nodes, num_labels]))\n",
    "    layer2_biases = tf.Variable(tf.zeros([num_labels]))    \n",
    "\n",
    "    # Training computation.\n",
    "    hidden_layer = tf.nn.relu(tf.matmul(tf_train_dataset, layer1_weights) + layer1_biases)\n",
    "    logits = tf.matmul(hidden_layer, layer2_weights) + layer2_biases\n",
    "    loss = tf.reduce_mean( \\\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits)) + \\\n",
    "    tf_l2_feature * (tf.nn.l2_loss(layer1_weights) + tf.nn.l2_loss(layer2_weights))\n",
    "\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    hidden_layer_valid_prediction = tf.nn.relu(tf.matmul(tf_valid_dataset, layer1_weights) + layer1_biases)\n",
    "    valid_prediction = tf.nn.softmax(\n",
    "    tf.matmul(hidden_layer_valid_prediction, layer2_weights) + layer2_biases)\n",
    "    hidden_layer_test_prediction = tf.nn.relu(tf.matmul(tf_test_dataset, layer1_weights) + layer1_biases)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(hidden_layer_test_prediction, layer2_weights) + layer2_biases)\n",
    "\n",
    "print('Tensorflow Graph created')\n",
    "\n",
    "num_steps = 3001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, tf_l2_feature: 1e-3}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "            print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "            print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "            valid_prediction.eval(), valid_labels))\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tunning the L2 Regularization constant\n",
      "Accuracy of 88.9% for L2 parameter constant of 0.000100\n",
      "Accuracy of 89.8% for L2 parameter constant of 0.000126\n",
      "Accuracy of 89.9% for L2 parameter constant of 0.000158\n",
      "Accuracy of 89.8% for L2 parameter constant of 0.000200\n",
      "Accuracy of 90.6% for L2 parameter constant of 0.000251\n",
      "Accuracy of 91.0% for L2 parameter constant of 0.000316\n",
      "Accuracy of 90.5% for L2 parameter constant of 0.000398\n",
      "Accuracy of 91.4% for L2 parameter constant of 0.000501\n",
      "Accuracy of 92.2% for L2 parameter constant of 0.000631\n",
      "Accuracy of 92.5% for L2 parameter constant of 0.000794\n",
      "Accuracy of 93.1% for L2 parameter constant of 0.001000\n",
      "Accuracy of 93.3% for L2 parameter constant of 0.001259\n",
      "Accuracy of 93.3% for L2 parameter constant of 0.001585\n",
      "Accuracy of 93.0% for L2 parameter constant of 0.001995\n",
      "Accuracy of 92.7% for L2 parameter constant of 0.002512\n",
      "Accuracy of 92.2% for L2 parameter constant of 0.003162\n",
      "Accuracy of 92.0% for L2 parameter constant of 0.003981\n",
      "Accuracy of 91.6% for L2 parameter constant of 0.005012\n",
      "Accuracy of 91.4% for L2 parameter constant of 0.006310\n",
      "Accuracy of 90.8% for L2 parameter constant of 0.007943\n"
     ]
    }
   ],
   "source": [
    "print('Tunning the L2 Regularization constant')\n",
    "\n",
    "num_steps = 3001\n",
    "l2_constant_values = [pow(10, i) for i in np.arange(-4, -2, 0.1)]\n",
    "accuracy_values = []\n",
    "max_accuracy, best_l2_constant = 0, 0\n",
    "\n",
    "for l2_constant in l2_constant_values:\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        tf.global_variables_initializer().run()\n",
    "        for step in range(num_steps):\n",
    "            # Pick an offset within the training data, which has been randomized.\n",
    "            # Note: we could use better randomization across epochs.\n",
    "            offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "            # Generate a minibatch.\n",
    "            batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "            batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "            # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "            # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "            # and the value is the numpy array to feed to it.\n",
    "            feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, tf_l2_feature: l2_constant}\n",
    "            _, l, predictions = session.run(\n",
    "              [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        test_accuracy = accuracy(test_prediction.eval(), test_labels)\n",
    "        if test_accuracy == max(accuracy_values, test_accuracy):\n",
    "            max_accuracy = test_accuracy\n",
    "            best_ls_constact = l2_constant\n",
    "        accuracy_values.append(test_accuracy)\n",
    "    print('Accuracy of %.2f%% for L2 parameter constant of %f' % (accuracy_values[-1], l2_constant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot the L2 Regularization loss for our Test\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEMCAYAAADNtWEcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSqkg9f8Degh0oKYhHQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10be80350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum accuracy is 0.00% with L2 Regularization constant of 0.000000\n"
     ]
    }
   ],
   "source": [
    "print('Plot the L2 Regularization loss for our Test')\n",
    "plt.semilogx(l2_constant_values, accuracy_values)\n",
    "plt.grid(True)\n",
    "plt.title('Accuracy against L2 regularization (1 Layer Neural Network)')\n",
    "plt.show()\n",
    "print('Maximum accuracy is %.2f%% with L2 Regularization constant of %f' % (max_accuracy, best_l2_constant))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "na8xX2yHZzNF"
   },
   "source": [
    "---\n",
    "Problem 2\n",
    "---------\n",
    "Let's demonstrate an extreme case of overfitting. Restrict your training data to just a few batches. What happens?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ww3SCBUdlkRc"
   },
   "source": [
    "---\n",
    "Problem 3\n",
    "---------\n",
    "Introduce Dropout on the hidden layer of the neural network. Remember: Dropout should only be introduced during training, not evaluation, otherwise your evaluation results would be stochastic as well. TensorFlow provides `nn.dropout()` for that, but you have to make sure it's only inserted during training.\n",
    "\n",
    "What happens to our extreme overfitting case?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-b1hTz3VWZjw"
   },
   "source": [
    "---\n",
    "Problem 4\n",
    "---------\n",
    "\n",
    "Try to get the best performance you can using a multi-layer model! The best reported test accuracy using a deep network is [97.1%](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html?showComment=1391023266211#c8758720086795711595).\n",
    "\n",
    "One avenue you can explore is to add multiple layers.\n",
    "\n",
    "Another one is to use learning rate decay:\n",
    "\n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    learning_rate = tf.train.exponential_decay(0.5, global_step, ...)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    " \n",
    " ---\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "3_regularization.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
