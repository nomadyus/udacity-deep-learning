{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kR-4eNdK6lYS"
   },
   "source": [
    "Deep Learning\n",
    "=============\n",
    "\n",
    "Assignment 3\n",
    "------------\n",
    "\n",
    "Previously in `2_fullyconnected.ipynb`, you trained a logistic regression and a neural network model.\n",
    "\n",
    "The goal of this assignment is to explore regularization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "JLpLa8Jt7Vu4"
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1HrCK6e17WzV"
   },
   "source": [
    "First reload the data we generated in `1_notmnist.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11777,
     "status": "ok",
     "timestamp": 1449849322348,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "y3-cj1bpmuxc",
    "outputId": "e03576f1-ebbe-4838-c388-f1777bcc9873"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28) (200000,)\n",
      "Validation set (10000, 28, 28) (10000,)\n",
      "Test set (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset = save['train_dataset']\n",
    "  train_labels = save['train_labels']\n",
    "  valid_dataset = save['valid_dataset']\n",
    "  valid_labels = save['valid_labels']\n",
    "  test_dataset = save['test_dataset']\n",
    "  test_labels = save['test_labels']\n",
    "  del save  # hint to help gc free up memory\n",
    "  print('Training set', train_dataset.shape, train_labels.shape)\n",
    "  print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "  print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7aHrm6nGDMB"
   },
   "source": [
    "Reformat into a shape that's more adapted to the models we're going to train:\n",
    "- data as a flat matrix,\n",
    "- labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11728,
     "status": "ok",
     "timestamp": 1449849322356,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "IRSyYiIIGIzS",
    "outputId": "3f8996ee-3574-4f44-c953-5c8a04636582"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 784) (200000, 10)\n",
      "Validation set (10000, 784) (10000, 10)\n",
      "Test set (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)\n",
    "  # Map 1 to [0.0, 1.0, 0.0 ...], 2 to [0.0, 0.0, 1.0 ...]\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "RajPLaL_ZW6w"
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sgLbUAQ1CW-1"
   },
   "source": [
    "---\n",
    "Problem 1\n",
    "---------\n",
    "\n",
    "Introduce and tune L2 regularization for both logistic and neural network models. Remember that L2 amounts to adding a penalty on the norm of the weights to the loss. In TensorFlow, you can compute the L2 loss for a tensor `t` using `nn.l2_loss(t)`. The right amount of regularization should improve your validation / test accuracy.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using L2 Regularization for Logistic Model\n",
      "Tensorflow Graph created\n",
      "Initialized\n",
      "Minibatch loss at step 0: 21.191835\n",
      "Minibatch accuracy: 5.5%\n",
      "Validation accuracy: 7.5%\n",
      "Minibatch loss at step 500: 2.362669\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 76.4%\n",
      "Minibatch loss at step 1000: 1.800544\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 78.4%\n",
      "Minibatch loss at step 1500: 0.934974\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 2000: 0.803659\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 2500: 0.829100\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 3000: 0.753053\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 81.6%\n",
      "Test accuracy: 88.9%\n"
     ]
    }
   ],
   "source": [
    "print('Using L2 Regularization for Logistic Model')\n",
    "batch_size = 128\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    tf_l2_feature = tf.placeholder(tf.float32)\n",
    "\n",
    "    # Variables.\n",
    "    weights = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    # Training computation.\n",
    "    logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "    loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits)) + tf_l2_feature * tf.nn.l2_loss(weights)\n",
    "\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(\n",
    "    tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)\n",
    "\n",
    "print('Tensorflow Graph created')\n",
    "\n",
    "num_steps = 3001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, tf_l2_feature: 1e-3}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "            print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "            print(\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tunning the L2 Regularization constant\n",
      "L2 Regularization constant of 0.000100 performed with 86.78% accuracy\n",
      "L2 Regularization constant of 0.000126 performed with 86.63% accuracy\n",
      "L2 Regularization constant of 0.000158 performed with 87.20% accuracy\n",
      "L2 Regularization constant of 0.000200 performed with 87.50% accuracy\n",
      "L2 Regularization constant of 0.000251 performed with 87.37% accuracy\n",
      "L2 Regularization constant of 0.000316 performed with 87.47% accuracy\n",
      "L2 Regularization constant of 0.000398 performed with 88.07% accuracy\n",
      "L2 Regularization constant of 0.000501 performed with 88.19% accuracy\n",
      "L2 Regularization constant of 0.000631 performed with 88.68% accuracy\n",
      "L2 Regularization constant of 0.000794 performed with 88.75% accuracy\n",
      "L2 Regularization constant of 0.001000 performed with 88.92% accuracy\n",
      "L2 Regularization constant of 0.001259 performed with 88.95% accuracy\n",
      "L2 Regularization constant of 0.001585 performed with 89.22% accuracy\n",
      "L2 Regularization constant of 0.001995 performed with 89.11% accuracy\n",
      "L2 Regularization constant of 0.002512 performed with 89.06% accuracy\n",
      "L2 Regularization constant of 0.003162 performed with 89.04% accuracy\n",
      "L2 Regularization constant of 0.003981 performed with 88.99% accuracy\n",
      "L2 Regularization constant of 0.005012 performed with 88.99% accuracy\n",
      "L2 Regularization constant of 0.006310 performed with 88.86% accuracy\n",
      "L2 Regularization constant of 0.007943 performed with 88.70% accuracy\n"
     ]
    }
   ],
   "source": [
    "print('Tunning the L2 Regularization constant')\n",
    "\n",
    "num_steps = 3001\n",
    "l2_constant_values = [pow(10, i) for i in np.arange(-4, -2, 0.1)]\n",
    "accuracy_values = []\n",
    "max_accuracy, best_l2_constant = 0, 0\n",
    "\n",
    "for l2_constant in l2_constant_values:\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        tf.global_variables_initializer().run()\n",
    "        for step in range(num_steps):\n",
    "            # Pick an offset within the training data, which has been randomized.\n",
    "            # Note: we could use better randomization across epochs.\n",
    "            offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "            # Generate a minibatch.\n",
    "            batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "            batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "            # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "            # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "            # and the value is the numpy array to feed to it.\n",
    "            feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, tf_l2_feature: l2_constant}\n",
    "            _, l, predictions = session.run(\n",
    "              [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        test_accuracy = accuracy(test_prediction.eval(), test_labels)\n",
    "        if test_accuracy == max(max_accuracy, test_accuracy):\n",
    "            max_accuracy = test_accuracy\n",
    "            best_l2_constant = l2_constant\n",
    "        accuracy_values.append(test_accuracy)\n",
    "        print('L2 Regularization constant of %f performed with %.2f%% accuracy' % (l2_constant, accuracy_values[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot the L2 Regularization loss for our Test\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEMCAYAAAAoB2Y1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3h4YbhqhEwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10faa4990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum accuracy is 89.22% with L2 Regularization constant of 0.001585\n"
     ]
    }
   ],
   "source": [
    "print('Plot the L2 Regularization loss for our Test')\n",
    "plt.semilogx(l2_constant_values, accuracy_values)\n",
    "plt.grid(True)\n",
    "plt.title('Accuracy against L2 regularization (Logistic Regression)')\n",
    "plt.show()\n",
    "print('Maximum accuracy is %.2f%% with L2 Regularization constant of %f' % (max_accuracy, best_l2_constant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using L2 Regularization for Neural Network Model (1 Layer)\n",
      "Tensorflow Graph created\n",
      "Initialized\n",
      "Minibatch loss at step 0: 645.319702\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 31.8%\n",
      "Minibatch loss at step 500: 196.499054\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 77.5%\n",
      "Minibatch loss at step 1000: 115.158943\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 1500: 68.722801\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 83.5%\n",
      "Minibatch loss at step 2000: 41.229263\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 85.3%\n",
      "Minibatch loss at step 2500: 25.131517\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 86.1%\n",
      "Minibatch loss at step 3000: 15.487769\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 86.6%\n",
      "Test accuracy: 92.9%\n"
     ]
    }
   ],
   "source": [
    "print('Using L2 Regularization for Neural Network Model (1 Hidden Layer)')\n",
    "batch_size = 128\n",
    "num_hidden_nodes = 1024\n",
    "\n",
    "# Buildig the Network\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    tf_l2_feature = tf.placeholder(tf.float32)\n",
    "\n",
    "    # Variables.\n",
    "    layer1_weights = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, num_hidden_nodes]))\n",
    "    layer1_biases = tf.Variable(tf.zeros([num_hidden_nodes]))\n",
    "    layer2_weights = tf.Variable(\n",
    "    tf.truncated_normal([num_hidden_nodes, num_labels]))\n",
    "    layer2_biases = tf.Variable(tf.zeros([num_labels]))    \n",
    "\n",
    "    # Training computation.\n",
    "    hidden_layer = tf.nn.relu(tf.matmul(tf_train_dataset, layer1_weights) + layer1_biases)\n",
    "    logits = tf.matmul(hidden_layer, layer2_weights) + layer2_biases\n",
    "    loss = tf.reduce_mean( \\\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits)) + \\\n",
    "    tf_l2_feature * (tf.nn.l2_loss(layer1_weights) + tf.nn.l2_loss(layer2_weights))\n",
    "\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    hidden_layer_valid_prediction = tf.nn.relu(tf.matmul(tf_valid_dataset, layer1_weights) + layer1_biases)\n",
    "    valid_prediction = tf.nn.softmax(\n",
    "    tf.matmul(hidden_layer_valid_prediction, layer2_weights) + layer2_biases)\n",
    "    hidden_layer_test_prediction = tf.nn.relu(tf.matmul(tf_test_dataset, layer1_weights) + layer1_biases)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(hidden_layer_test_prediction, layer2_weights) + layer2_biases)\n",
    "\n",
    "print('Tensorflow Graph created')\n",
    "\n",
    "num_steps = 3001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, tf_l2_feature: 1e-3}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "            print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "            print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "            valid_prediction.eval(), valid_labels))\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tunning the L2 Regularization constant\n",
      "Accuracy of 89.87% for L2 parameter constant of 0.000100\n",
      "Accuracy of 89.84% for L2 parameter constant of 0.000126\n",
      "Accuracy of 90.38% for L2 parameter constant of 0.000158\n",
      "Accuracy of 90.21% for L2 parameter constant of 0.000200\n",
      "Accuracy of 90.71% for L2 parameter constant of 0.000251\n",
      "Accuracy of 90.75% for L2 parameter constant of 0.000316\n",
      "Accuracy of 91.00% for L2 parameter constant of 0.000398\n",
      "Accuracy of 91.40% for L2 parameter constant of 0.000501\n",
      "Accuracy of 92.39% for L2 parameter constant of 0.000631\n",
      "Accuracy of 92.81% for L2 parameter constant of 0.000794\n",
      "Accuracy of 93.03% for L2 parameter constant of 0.001000\n",
      "Accuracy of 92.90% for L2 parameter constant of 0.001259\n",
      "Accuracy of 93.31% for L2 parameter constant of 0.001585\n",
      "Accuracy of 93.03% for L2 parameter constant of 0.001995\n",
      "Accuracy of 92.78% for L2 parameter constant of 0.002512\n",
      "Accuracy of 92.49% for L2 parameter constant of 0.003162\n",
      "Accuracy of 92.02% for L2 parameter constant of 0.003981\n",
      "Accuracy of 91.69% for L2 parameter constant of 0.005012\n",
      "Accuracy of 91.29% for L2 parameter constant of 0.006310\n",
      "Accuracy of 90.73% for L2 parameter constant of 0.007943\n"
     ]
    }
   ],
   "source": [
    "print('Tunning the L2 Regularization constant with 1 Hidden Layer')\n",
    "\n",
    "num_steps = 3001\n",
    "l2_constant_values = [pow(10, i) for i in np.arange(-4, -2, 0.1)]\n",
    "accuracy_values = []\n",
    "max_accuracy, best_l2_constant = 0, 0\n",
    "\n",
    "for l2_constant in l2_constant_values:\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        tf.global_variables_initializer().run()\n",
    "        for step in range(num_steps):\n",
    "            # Pick an offset within the training data, which has been randomized.\n",
    "            # Note: we could use better randomization across epochs.\n",
    "            offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "            # Generate a minibatch.\n",
    "            batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "            batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "            # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "            # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "            # and the value is the numpy array to feed to it.\n",
    "            feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, tf_l2_feature: l2_constant}\n",
    "            _, l, predictions = session.run(\n",
    "              [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        test_accuracy = accuracy(test_prediction.eval(), test_labels)\n",
    "        if test_accuracy == max(max_accuracy, test_accuracy):\n",
    "            max_accuracy = test_accuracy\n",
    "            best_l2_constant = l2_constant\n",
    "        accuracy_values.append(test_accuracy)\n",
    "    print('Accuracy of %.2f%% for L2 parameter constant of %f' % (accuracy_values[-1], l2_constant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot the L2 Regularization loss for our Test\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEMCAYAAAAxoErWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10fce1f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum accuracy is 0.00% with L2 Regularization constant of 0.000000\n"
     ]
    }
   ],
   "source": [
    "print('Plot the L2 Regularization loss for our Test')\n",
    "plt.semilogx(l2_constant_values, accuracy_values)\n",
    "plt.grid(True)\n",
    "plt.title('Accuracy against L2 regularization (1 Hidden Layer Neural Network)')\n",
    "plt.show()\n",
    "print('Maximum accuracy is %.2f%% with L2 Regularization constant of %f' % (max_accuracy, best_l2_constant))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "na8xX2yHZzNF"
   },
   "source": [
    "---\n",
    "Problem 2\n",
    "---------\n",
    "Let's demonstrate an extreme case of overfitting. Restrict your training data to just a few batches. What happens?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using L2 Regularization for Neural Network Model (1 Layer) with overfitting\n",
      "Tensorflow Graph created\n",
      "Initialized\n",
      "Minibatch loss at step 0: 415.654114\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 32.1%\n",
      "Minibatch loss at step 1: 1396.770386\n",
      "Minibatch accuracy: 25.8%\n",
      "Validation accuracy: 34.4%\n",
      "Minibatch loss at step 2: 2438.612793\n",
      "Minibatch accuracy: 36.7%\n",
      "Validation accuracy: 31.0%\n",
      "Minibatch loss at step 3: 867.941528\n",
      "Minibatch accuracy: 23.4%\n",
      "Validation accuracy: 47.4%\n",
      "Minibatch loss at step 4: 668.226318\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 54.2%\n",
      "Minibatch loss at step 5: 466.870239\n",
      "Minibatch accuracy: 55.5%\n",
      "Validation accuracy: 66.0%\n",
      "Minibatch loss at step 6: 247.263153\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 70.0%\n",
      "Minibatch loss at step 7: 170.861816\n",
      "Minibatch accuracy: 64.8%\n",
      "Validation accuracy: 63.8%\n",
      "Minibatch loss at step 8: 306.140686\n",
      "Minibatch accuracy: 60.9%\n",
      "Validation accuracy: 66.8%\n",
      "Minibatch loss at step 9: 203.198593\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 74.3%\n",
      "Minibatch loss at step 10: 162.390411\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 75.3%\n",
      "Minibatch loss at step 11: 65.934525\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 12: 42.582008\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 75.0%\n",
      "Minibatch loss at step 13: 74.492104\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 75.2%\n",
      "Minibatch loss at step 14: 125.908501\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 72.6%\n",
      "Minibatch loss at step 15: 119.464905\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 74.2%\n",
      "Minibatch loss at step 16: 104.822083\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 75.6%\n",
      "Minibatch loss at step 17: 56.166691\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 74.8%\n",
      "Minibatch loss at step 18: 84.306938\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 68.9%\n",
      "Minibatch loss at step 19: 78.717491\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 74.3%\n",
      "Minibatch loss at step 20: 108.990494\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 73.6%\n",
      "Minibatch loss at step 21: 53.475121\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 76.9%\n",
      "Minibatch loss at step 22: 45.583199\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 74.1%\n",
      "Minibatch loss at step 23: 76.150276\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 72.4%\n",
      "Minibatch loss at step 24: 64.939407\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 75.8%\n",
      "Minibatch loss at step 25: 113.944824\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 26: 79.626060\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 75.6%\n",
      "Minibatch loss at step 27: 99.740952\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 76.4%\n",
      "Minibatch loss at step 28: 52.192238\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 74.8%\n",
      "Minibatch loss at step 29: 69.151657\n",
      "Minibatch accuracy: 66.4%\n",
      "Validation accuracy: 77.0%\n",
      "Minibatch loss at step 30: 50.626892\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 77.9%\n",
      "Minibatch loss at step 31: 33.757591\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 32: 76.161697\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 77.4%\n",
      "Minibatch loss at step 33: 29.033482\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 75.9%\n",
      "Minibatch loss at step 34: 65.947998\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 73.9%\n",
      "Minibatch loss at step 35: 49.250919\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 77.0%\n",
      "Minibatch loss at step 36: 80.874313\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 76.0%\n",
      "Minibatch loss at step 37: 60.610203\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 76.4%\n",
      "Minibatch loss at step 38: 51.989162\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 75.1%\n",
      "Minibatch loss at step 39: 112.683762\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 76.7%\n",
      "Minibatch loss at step 40: 100.060349\n",
      "Minibatch accuracy: 67.2%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 41: 56.448936\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 76.9%\n",
      "Minibatch loss at step 42: 39.509476\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 76.0%\n",
      "Minibatch loss at step 43: 78.346939\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 70.1%\n",
      "Minibatch loss at step 44: 142.981506\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 74.3%\n",
      "Minibatch loss at step 45: 75.523499\n",
      "Minibatch accuracy: 69.5%\n",
      "Validation accuracy: 69.4%\n",
      "Minibatch loss at step 46: 114.428177\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 74.1%\n",
      "Minibatch loss at step 47: 35.137672\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 75.3%\n",
      "Minibatch loss at step 48: 77.543411\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 74.8%\n",
      "Minibatch loss at step 49: 57.916885\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 70.4%\n",
      "Minibatch loss at step 50: 46.778114\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 76.6%\n",
      "Minibatch loss at step 51: 48.005924\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 76.2%\n",
      "Minibatch loss at step 52: 31.303043\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 78.1%\n",
      "Minibatch loss at step 53: 66.269432\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 76.6%\n",
      "Minibatch loss at step 54: 51.638138\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 76.5%\n",
      "Minibatch loss at step 55: 38.227119\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 78.5%\n",
      "Minibatch loss at step 56: 52.738190\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 76.7%\n",
      "Minibatch loss at step 57: 70.172287\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 75.7%\n",
      "Minibatch loss at step 58: 71.799591\n",
      "Minibatch accuracy: 69.5%\n",
      "Validation accuracy: 75.3%\n",
      "Minibatch loss at step 59: 66.055481\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 77.1%\n",
      "Minibatch loss at step 60: 43.847496\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 76.0%\n",
      "Minibatch loss at step 61: 39.583969\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 77.2%\n",
      "Minibatch loss at step 62: 43.634476\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 77.2%\n",
      "Minibatch loss at step 63: 21.777157\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 77.1%\n",
      "Minibatch loss at step 64: 28.518398\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 65: 35.623405\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 75.9%\n",
      "Minibatch loss at step 66: 39.476440\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 72.3%\n",
      "Minibatch loss at step 67: 73.017311\n",
      "Minibatch accuracy: 66.4%\n",
      "Validation accuracy: 77.7%\n",
      "Minibatch loss at step 68: 44.652122\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 78.7%\n",
      "Minibatch loss at step 69: 62.604351\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 74.8%\n",
      "Minibatch loss at step 70: 57.845688\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 74.2%\n",
      "Minibatch loss at step 71: 93.662491\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 76.1%\n",
      "Minibatch loss at step 72: 58.787727\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 74.8%\n",
      "Minibatch loss at step 73: 49.236809\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 74: 50.760315\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 78.5%\n",
      "Minibatch loss at step 75: 22.563740\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 78.3%\n",
      "Minibatch loss at step 76: 54.215168\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 78.1%\n",
      "Minibatch loss at step 77: 18.586460\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 78.1%\n",
      "Minibatch loss at step 78: 35.899784\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 76.3%\n",
      "Minibatch loss at step 79: 41.527798\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 78.7%\n",
      "Minibatch loss at step 80: 42.227043\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 77.2%\n",
      "Minibatch loss at step 81: 49.179733\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 78.7%\n",
      "Minibatch loss at step 82: 36.608536\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 76.8%\n",
      "Minibatch loss at step 83: 47.022564\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 75.0%\n",
      "Minibatch loss at step 84: 44.924324\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 77.5%\n",
      "Minibatch loss at step 85: 32.928299\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 77.3%\n",
      "Minibatch loss at step 86: 47.744892\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 77.0%\n",
      "Minibatch loss at step 87: 24.784472\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 76.8%\n",
      "Minibatch loss at step 88: 33.978737\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 78.5%\n",
      "Minibatch loss at step 89: 34.967659\n",
      "Minibatch accuracy: 74.2%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 77.5%\n",
      "Minibatch loss at step 90: 14.857161\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 78.4%\n",
      "Minibatch loss at step 91: 15.130486\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 76.8%\n",
      "Minibatch loss at step 92: 36.732830\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 76.7%\n",
      "Minibatch loss at step 93: 40.709412\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 75.1%\n",
      "Minibatch loss at step 94: 45.540543\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 74.2%\n",
      "Minibatch loss at step 95: 49.184685\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 76.2%\n",
      "Minibatch loss at step 96: 37.302441\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 77.2%\n",
      "Minibatch loss at step 97: 51.089226\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 78.9%\n",
      "Minibatch loss at step 98: 36.782379\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 78.7%\n",
      "Minibatch loss at step 99: 20.610994\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 100: 18.469290\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 77.8%\n",
      "Test accuracy: 85.0%\n"
     ]
    }
   ],
   "source": [
    "print('Using L2 Regularization for Neural Network Model (1 Hidden Layer) with overfitting')\n",
    "batch_size = 128\n",
    "num_hidden_nodes = 1024\n",
    "\n",
    "# Buildig the Network\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    tf_l2_feature = tf.placeholder(tf.float32)\n",
    "\n",
    "    # Variables.\n",
    "    layer1_weights = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, num_hidden_nodes]))\n",
    "    layer1_biases = tf.Variable(tf.zeros([num_hidden_nodes]))\n",
    "    layer2_weights = tf.Variable(\n",
    "    tf.truncated_normal([num_hidden_nodes, num_labels]))\n",
    "    layer2_biases = tf.Variable(tf.zeros([num_labels]))    \n",
    "\n",
    "    # Training computation.\n",
    "    hidden_layer = tf.nn.relu(tf.matmul(tf_train_dataset, layer1_weights) + layer1_biases)\n",
    "    logits = tf.matmul(hidden_layer, layer2_weights) + layer2_biases\n",
    "    loss = tf.reduce_mean( \\\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits)) + \\\n",
    "    tf_l2_feature * (tf.nn.l2_loss(layer1_weights) + tf.nn.l2_loss(layer2_weights))\n",
    "\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    hidden_layer_valid_prediction = tf.nn.relu(tf.matmul(tf_valid_dataset, layer1_weights) + layer1_biases)\n",
    "    valid_prediction = tf.nn.softmax(\n",
    "    tf.matmul(hidden_layer_valid_prediction, layer2_weights) + layer2_biases)\n",
    "    hidden_layer_test_prediction = tf.nn.relu(tf.matmul(tf_test_dataset, layer1_weights) + layer1_biases)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(hidden_layer_test_prediction, layer2_weights) + layer2_biases)\n",
    "\n",
    "print('Tensorflow Graph created')\n",
    "\n",
    "num_steps = 101\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, tf_l2_feature: best_l2_constant}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)        \n",
    "        print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "        print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "        print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tunning the L2 Regularization constant\n",
      "Accuracy of 86.46% for L2 parameter constant of 0.000100\n",
      "Accuracy of 85.25% for L2 parameter constant of 0.000126\n",
      "Accuracy of 85.60% for L2 parameter constant of 0.000158\n",
      "Accuracy of 86.36% for L2 parameter constant of 0.000200\n",
      "Accuracy of 84.82% for L2 parameter constant of 0.000251\n",
      "Accuracy of 84.93% for L2 parameter constant of 0.000316\n",
      "Accuracy of 85.31% for L2 parameter constant of 0.000398\n",
      "Accuracy of 84.92% for L2 parameter constant of 0.000501\n",
      "Accuracy of 86.15% for L2 parameter constant of 0.000631\n",
      "Accuracy of 83.56% for L2 parameter constant of 0.000794\n",
      "Accuracy of 84.98% for L2 parameter constant of 0.001000\n",
      "Accuracy of 86.06% for L2 parameter constant of 0.001259\n",
      "Accuracy of 86.83% for L2 parameter constant of 0.001585\n",
      "Accuracy of 84.14% for L2 parameter constant of 0.001995\n",
      "Accuracy of 85.69% for L2 parameter constant of 0.002512\n",
      "Accuracy of 86.52% for L2 parameter constant of 0.003162\n",
      "Accuracy of 87.04% for L2 parameter constant of 0.003981\n",
      "Accuracy of 85.52% for L2 parameter constant of 0.005012\n",
      "Accuracy of 86.95% for L2 parameter constant of 0.006310\n",
      "Accuracy of 87.00% for L2 parameter constant of 0.007943\n"
     ]
    }
   ],
   "source": [
    "print('Tunning the L2 Regularization constant')\n",
    "\n",
    "num_steps = 101\n",
    "l2_constant_values = [pow(10, i) for i in np.arange(-4, -2, 0.1)]\n",
    "accuracy_values = []\n",
    "max_accuracy, best_l2_constant = 0, 0\n",
    "\n",
    "for l2_constant in l2_constant_values:\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        tf.global_variables_initializer().run()\n",
    "        for step in range(num_steps):\n",
    "            # Pick an offset within the training data, which has been randomized.\n",
    "            # Note: we could use better randomization across epochs.\n",
    "            offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "            # Generate a minibatch.\n",
    "            batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "            batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "            # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "            # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "            # and the value is the numpy array to feed to it.\n",
    "            feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, tf_l2_feature: l2_constant}\n",
    "            _, l, predictions = session.run(\n",
    "              [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        test_accuracy = accuracy(test_prediction.eval(), test_labels)\n",
    "        if test_accuracy == max(max_accuracy, test_accuracy):\n",
    "            max_accuracy = test_accuracy\n",
    "            best_l2_constant = l2_constant\n",
    "        accuracy_values.append(test_accuracy)\n",
    "    print('Accuracy of %.2f%% for L2 parameter constant of %f' % (accuracy_values[-1], l2_constant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot the L2 Regularization loss for our Test\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdsAAAEMCAYAAACMQRyjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14b7617d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum accuracy is 87.04% with L2 Regularization constant of 0.003981\n"
     ]
    }
   ],
   "source": [
    "print('Plot the L2 Regularization loss for our Test')\n",
    "plt.semilogx(l2_constant_values, accuracy_values)\n",
    "plt.grid(True)\n",
    "plt.title('Accuracy against L2 regularization (1 Hidden Layer Neural Network) with overfitting')\n",
    "plt.show()\n",
    "print('Maximum accuracy is %.2f%% with L2 Regularization constant of %f' % (max_accuracy, best_l2_constant))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ww3SCBUdlkRc"
   },
   "source": [
    "---\n",
    "Problem 3\n",
    "---------\n",
    "Introduce Dropout on the hidden layer of the neural network. Remember: Dropout should only be introduced during training, not evaluation, otherwise your evaluation results would be stochastic as well. TensorFlow provides `nn.dropout()` for that, but you have to make sure it's only inserted during training.\n",
    "\n",
    "What happens to our extreme overfitting case?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using L2 Regularization for Neural Network Model (1 Layer) with Dropout\n",
      "Tensorflow Graph created\n",
      "Initialized\n",
      "Minibatch loss at step 0: 810.623657\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 38.8%\n",
      "Minibatch loss at step 500: 208.655304\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 79.7%\n",
      "Minibatch loss at step 1000: 117.830223\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 1500: 69.159241\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 2000: 41.376431\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 83.5%\n",
      "Minibatch loss at step 2500: 25.264975\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 84.6%\n",
      "Minibatch loss at step 3000: 15.554621\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 85.2%\n",
      "Test accuracy: 91.8%\n"
     ]
    }
   ],
   "source": [
    "print('Using L2 Regularization for Neural Network Model (1 Hidden Layer) with Dropout')\n",
    "batch_size = 128\n",
    "num_hidden_nodes = 1024\n",
    "dropout_rate = 0.5\n",
    "\n",
    "# Buildig the Network\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    tf_l2_feature = tf.placeholder(tf.float32)\n",
    "\n",
    "    # Variables.\n",
    "    layer1_weights = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, num_hidden_nodes]))\n",
    "    layer1_biases = tf.Variable(tf.zeros([num_hidden_nodes]))\n",
    "    layer2_weights = tf.Variable(\n",
    "    tf.truncated_normal([num_hidden_nodes, num_labels]))\n",
    "    layer2_biases = tf.Variable(tf.zeros([num_labels]))    \n",
    "\n",
    "    # Training computation.\n",
    "    hidden_layer = tf.nn.relu(tf.matmul(tf_train_dataset, layer1_weights) + layer1_biases)\n",
    "    hidden_layer_with_dropout = tf.nn.dropout(hidden_layer, dropout_rate)\n",
    "    logits = tf.matmul(hidden_layer_with_dropout, layer2_weights) + layer2_biases\n",
    "    loss = tf.reduce_mean( \\\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits)) + \\\n",
    "    tf_l2_feature * (tf.nn.l2_loss(layer1_weights) + tf.nn.l2_loss(layer2_weights))\n",
    "\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    hidden_layer_valid_prediction = tf.nn.relu(tf.matmul(tf_valid_dataset, layer1_weights) + layer1_biases)\n",
    "    valid_prediction = tf.nn.softmax(\n",
    "    tf.matmul(hidden_layer_valid_prediction, layer2_weights) + layer2_biases)\n",
    "    hidden_layer_test_prediction = tf.nn.relu(tf.matmul(tf_test_dataset, layer1_weights) + layer1_biases)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(hidden_layer_test_prediction, layer2_weights) + layer2_biases)\n",
    "\n",
    "print('Tensorflow Graph created')\n",
    "\n",
    "num_steps = 3001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, tf_l2_feature: 1e-3}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "            print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "            print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "            valid_prediction.eval(), valid_labels))\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tunning the L2 Regularization constant with Dropout\n",
      "Accuracy of 87.92% for L2 parameter constant of 0.000100\n",
      "Accuracy of 87.78% for L2 parameter constant of 0.000126\n",
      "Accuracy of 88.01% for L2 parameter constant of 0.000158\n",
      "Accuracy of 88.18% for L2 parameter constant of 0.000200\n",
      "Accuracy of 88.95% for L2 parameter constant of 0.000251\n",
      "Accuracy of 89.29% for L2 parameter constant of 0.000316\n",
      "Accuracy of 89.05% for L2 parameter constant of 0.000398\n",
      "Accuracy of 90.15% for L2 parameter constant of 0.000501\n",
      "Accuracy of 91.22% for L2 parameter constant of 0.000631\n",
      "Accuracy of 91.62% for L2 parameter constant of 0.000794\n",
      "Accuracy of 91.86% for L2 parameter constant of 0.001000\n",
      "Accuracy of 92.13% for L2 parameter constant of 0.001259\n",
      "Accuracy of 92.08% for L2 parameter constant of 0.001585\n",
      "Accuracy of 92.29% for L2 parameter constant of 0.001995\n",
      "Accuracy of 92.12% for L2 parameter constant of 0.002512\n",
      "Accuracy of 91.66% for L2 parameter constant of 0.003162\n",
      "Accuracy of 91.24% for L2 parameter constant of 0.003981\n",
      "Accuracy of 91.14% for L2 parameter constant of 0.005012\n",
      "Accuracy of 90.67% for L2 parameter constant of 0.006310\n",
      "Accuracy of 90.15% for L2 parameter constant of 0.007943\n"
     ]
    }
   ],
   "source": [
    "print('Tunning the L2 Regularization constant with Dropout')\n",
    "\n",
    "l2_constant_values = [pow(10, i) for i in np.arange(-4, -2, 0.1)]\n",
    "accuracy_values = []\n",
    "max_accuracy, best_l2_constant = 0, 0\n",
    "\n",
    "for l2_constant in l2_constant_values:\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        tf.global_variables_initializer().run()\n",
    "        for step in range(num_steps):\n",
    "            # Pick an offset within the training data, which has been randomized.\n",
    "            # Note: we could use better randomization across epochs.\n",
    "            offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "            # Generate a minibatch.\n",
    "            batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "            batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "            # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "            # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "            # and the value is the numpy array to feed to it.\n",
    "            feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, tf_l2_feature: l2_constant}\n",
    "            _, l, predictions = session.run(\n",
    "              [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        test_accuracy = accuracy(test_prediction.eval(), test_labels)\n",
    "        if test_accuracy == max(max_accuracy, test_accuracy):\n",
    "            max_accuracy = test_accuracy\n",
    "            best_l2_constant = l2_constant\n",
    "        accuracy_values.append(test_accuracy)\n",
    "    print('Accuracy of %.2f%% for L2 parameter constant of %f' % (accuracy_values[-1], l2_constant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot the L2 Regularization loss for our Test\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfwAAAEMCAYAAAAhwAQKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cbd4cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum accuracy is 92.29% with L2 Regularization constant of 0.001995\n"
     ]
    }
   ],
   "source": [
    "print('Plot the L2 Regularization loss for our Test')\n",
    "plt.semilogx(l2_constant_values, accuracy_values)\n",
    "plt.grid(True)\n",
    "plt.title('Accuracy against L2 regularization (1 Hidden Layer Neural Network) with Dropout')\n",
    "plt.show()\n",
    "print('Maximum accuracy is %.2f%% with L2 Regularization constant of %f' % (max_accuracy, best_l2_constant))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-b1hTz3VWZjw"
   },
   "source": [
    "---\n",
    "Problem 4\n",
    "---------\n",
    "\n",
    "Try to get the best performance you can using a multi-layer model! The best reported test accuracy using a deep network is [97.1%](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html?showComment=1391023266211#c8758720086795711595).\n",
    "\n",
    "One avenue you can explore is to add multiple layers.\n",
    "\n",
    "Another one is to use learning rate decay:\n",
    "\n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    learning_rate = tf.train.exponential_decay(0.5, global_step, ...)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    " \n",
    " ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using L2 Regularization for Neural Network Model (2 Hidden Layer Network)\n",
      "Tensorflow Graph created\n",
      "Initialized\n",
      "Minibatch loss at step 0: 4.411750\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 27.7%\n",
      "Minibatch loss at step 500: 1.104148\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 85.7%\n",
      "Minibatch loss at step 1000: 0.996774\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 86.3%\n",
      "Minibatch loss at step 1500: 0.603578\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 2000: 0.509534\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 2500: 0.548968\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 88.0%\n"
     ]
    }
   ],
   "source": [
    "print('Using L2 Regularization for Neural Network Model (2 Hidden Layer Network)')\n",
    "batch_size = 128\n",
    "num_first_hidden_nodes = 1024\n",
    "num_last_hidden_nodes = 200\n",
    "dropout_rate = 0.5\n",
    "\n",
    "# Building the Network\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,\n",
    "        shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    tf_l2_feature = tf.placeholder(tf.float32)\n",
    "    # Global step for learning rate\n",
    "    global_step = tf.Variable(0)\n",
    "\n",
    "    # Variables.\n",
    "    layer1_weights = tf.Variable( \\\n",
    "        tf.truncated_normal([image_size * image_size, num_first_hidden_nodes],\n",
    "        stddev=np.sqrt(2.0 / (image_size * image_size))))\n",
    "    layer1_biases = tf.Variable(tf.zeros([num_first_hidden_nodes]))\n",
    "    layer2_weights = tf.Variable( \\\n",
    "        tf.truncated_normal([num_first_hidden_nodes, num_last_hidden_nodes], \n",
    "        stddev=np.sqrt(2.0 / num_first_hidden_nodes)))\n",
    "    layer2_biases = tf.Variable(tf.zeros([num_last_hidden_nodes])) \n",
    "    last_layer_weights = tf.Variable( \\\n",
    "        tf.truncated_normal([num_last_hidden_nodes, num_labels], \n",
    "        stddev=np.sqrt(2.0 / num_labels)))\n",
    "    last_layer_biases = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    # Training computation.\n",
    "    first_hidden_layer = tf.nn.relu(tf.matmul(tf_train_dataset, layer1_weights) + layer1_biases)\n",
    "    last_hidden_layer = tf.nn.relu(tf.matmul(first_hidden_layer, layer2_weights) + layer2_biases)\n",
    "    logits = tf.matmul(last_hidden_layer, last_layer_weights) + last_layer_biases\n",
    "    \n",
    "    loss = tf.reduce_mean( \\\n",
    "        tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits)) + \\\n",
    "        tf_l2_feature * (tf.nn.l2_loss(layer1_weights) + tf.nn.l2_loss(layer2_weights) +  \\\n",
    "        tf.nn.l2_loss(last_layer_weights))\n",
    "\n",
    "    # Learning Rate\n",
    "    learning_rate = tf.train.exponential_decay(0.5, global_step, 1000, 0.65, staircase=True)\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    \n",
    "    first_hidden_layer_valid_prediction = tf.nn.relu(tf.matmul(tf_valid_dataset, layer1_weights) + layer1_biases)\n",
    "    last_hidden_layer_valid_prediction = tf.nn.relu( \\\n",
    "        tf.matmul(first_hidden_layer_valid_prediction, layer2_weights) + layer2_biases)\n",
    "    valid_prediction = tf.nn.softmax( \\\n",
    "        tf.matmul(last_hidden_layer_valid_prediction, last_layer_weights) + last_layer_biases)\n",
    "    \n",
    "    first_hidden_layer_test_prediction = tf.nn.relu(tf.matmul(tf_test_dataset, layer1_weights) + layer1_biases)\n",
    "    last_hidden_layer_test_prediction = tf.nn.relu( \\\n",
    "        tf.matmul(first_hidden_layer_test_prediction, layer2_weights) + layer2_biases)\n",
    "    test_prediction = tf.nn.softmax( \\\n",
    "        tf.matmul(last_hidden_layer_test_prediction, last_layer_weights) + last_layer_biases)\n",
    "\n",
    "    \n",
    "print('Tensorflow Graph created')\n",
    "\n",
    "num_steps = 3001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, tf_l2_feature: 1e-3}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "            print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "            print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "            valid_prediction.eval(), valid_labels))\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tunning the L2 Regularization constant\n",
      "Accuracy of 93.52% for L2 parameter constant of 0.000100\n",
      "Accuracy of 94.67% for L2 parameter constant of 0.000126\n",
      "Accuracy of 94.19% for L2 parameter constant of 0.000158\n",
      "Accuracy of 94.41% for L2 parameter constant of 0.000200\n",
      "Accuracy of 94.10% for L2 parameter constant of 0.000251\n",
      "Accuracy of 93.93% for L2 parameter constant of 0.000316\n",
      "Accuracy of 94.35% for L2 parameter constant of 0.000398\n",
      "Accuracy of 94.29% for L2 parameter constant of 0.000501\n",
      "Accuracy of 94.16% for L2 parameter constant of 0.000631\n",
      "Accuracy of 94.13% for L2 parameter constant of 0.000794\n",
      "Accuracy of 94.13% for L2 parameter constant of 0.001000\n",
      "Accuracy of 93.89% for L2 parameter constant of 0.001259\n",
      "Accuracy of 93.40% for L2 parameter constant of 0.001585\n",
      "Accuracy of 93.38% for L2 parameter constant of 0.001995\n",
      "Accuracy of 92.96% for L2 parameter constant of 0.002512\n",
      "Accuracy of 92.70% for L2 parameter constant of 0.003162\n",
      "Accuracy of 92.13% for L2 parameter constant of 0.003981\n",
      "Accuracy of 92.04% for L2 parameter constant of 0.005012\n",
      "Accuracy of 91.59% for L2 parameter constant of 0.006310\n",
      "Accuracy of 91.15% for L2 parameter constant of 0.007943\n"
     ]
    }
   ],
   "source": [
    "print('Tunning the L2 Regularization constant')\n",
    "\n",
    "l2_constant_values = [pow(10, i) for i in np.arange(-4, -2, 0.1)]\n",
    "accuracy_values = []\n",
    "max_accuracy, best_l2_constant = 0, 0\n",
    "\n",
    "for l2_constant in l2_constant_values:\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        tf.global_variables_initializer().run()\n",
    "        for step in range(num_steps):\n",
    "            # Pick an offset within the training data, which has been randomized.\n",
    "            # Note: we could use better randomization across epochs.\n",
    "            offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "            # Generate a minibatch.\n",
    "            batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "            batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "            # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "            # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "            # and the value is the numpy array to feed to it.\n",
    "            feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, tf_l2_feature: l2_constant}\n",
    "            _, l, predictions = session.run(\n",
    "              [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        test_accuracy = accuracy(test_prediction.eval(), test_labels)\n",
    "        if test_accuracy == max(max_accuracy, test_accuracy):\n",
    "            max_accuracy = test_accuracy\n",
    "            best_l2_constant = l2_constant\n",
    "        accuracy_values.append(test_accuracy)\n",
    "    print('Accuracy of %.2f%% for L2 parameter constant of %f' % (accuracy_values[-1], l2_constant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot the L2 Regularization loss for our Test\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEMCAYAAADj8ECOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBIQlFGOMMQFhCcUYY0xA/H9x02/fcAzl6wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10fcd1490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum accuracy is 94.67% with L2 Regularization constant of 0.000126\n"
     ]
    }
   ],
   "source": [
    "print('Plot the L2 Regularization loss for our Test')\n",
    "plt.semilogx(l2_constant_values, accuracy_values)\n",
    "plt.grid(True)\n",
    "plt.title('Accuracy against L2 regularization (Multi Layer Neural Network)')\n",
    "plt.show()\n",
    "print('Maximum accuracy is %.2f%% with L2 Regularization constant of %f' % (max_accuracy, best_l2_constant))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 2 Hidden Layers with 1024, 200 nodes gave an accuracy of 94.67% using a L2 Regularization value of 0.000126.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Using L2 Regularization for Neural Network Model (2 Hidden Layer Network)')\n",
    "batch_size = 128\n",
    "num_first_hidden_nodes = 1024\n",
    "num_last_hidden_nodes = 200\n",
    "dropout_rate = 0.5\n",
    "\n",
    "# Building the Network\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,\n",
    "        shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    tf_l2_feature = tf.placeholder(tf.float32)\n",
    "    # Global step for learning rate\n",
    "    global_step = tf.Variable(0)\n",
    "\n",
    "    # Variables.\n",
    "    layer1_weights = tf.Variable( \\\n",
    "        tf.truncated_normal([image_size * image_size, num_first_hidden_nodes],\n",
    "        stddev=np.sqrt(2.0 / (image_size * image_size))))\n",
    "    layer1_biases = tf.Variable(tf.zeros([num_first_hidden_nodes]))\n",
    "    layer2_weights = tf.Variable( \\\n",
    "        tf.truncated_normal([num_first_hidden_nodes, num_last_hidden_nodes], \n",
    "        stddev=np.sqrt(2.0 / num_first_hidden_nodes)))\n",
    "    layer2_biases = tf.Variable(tf.zeros([num_last_hidden_nodes])) \n",
    "    last_layer_weights = tf.Variable( \\\n",
    "        tf.truncated_normal([num_last_hidden_nodes, num_labels], \n",
    "        stddev=np.sqrt(2.0 / num_labels)))\n",
    "    last_layer_biases = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    # Training computation.\n",
    "    first_hidden_layer = tf.nn.relu(tf.matmul(tf_train_dataset, layer1_weights) + layer1_biases)\n",
    "#     first_hidden_layer_with_dropout = tf.nn.dropout(first_hidden_layer, dropout_rate)    \n",
    "    last_hidden_layer = tf.nn.relu(tf.matmul(first_hidden_layer, layer2_weights) + layer2_biases)    \n",
    "#     last_hidden_layer_with_dropout = tf.nn.dropout(last_hidden_layer, dropout_rate)\n",
    "    logits = tf.matmul(last_hidden_layer, last_layer_weights) + last_layer_biases\n",
    "    \n",
    "    loss = tf.reduce_mean( \\\n",
    "        tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits)) + \\\n",
    "        tf_l2_feature * (tf.nn.l2_loss(layer1_weights) + tf.nn.l2_loss(layer2_weights) +  \\\n",
    "        tf.nn.l2_loss(last_layer_weights))\n",
    "\n",
    "    # Learning Rate\n",
    "    learning_rate = tf.train.exponential_decay(0.5, global_step, 1000, 0.65, staircase=True)\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    \n",
    "    first_hidden_layer_valid_prediction = tf.nn.relu(tf.matmul(tf_valid_dataset, layer1_weights) + layer1_biases)\n",
    "    last_hidden_layer_valid_prediction = tf.nn.relu( \\\n",
    "        tf.matmul(first_hidden_layer_valid_prediction, layer2_weights) + layer2_biases)\n",
    "    valid_prediction = tf.nn.softmax( \\\n",
    "        tf.matmul(last_hidden_layer_valid_prediction, last_layer_weights) + last_layer_biases)\n",
    "    \n",
    "    first_hidden_layer_test_prediction = tf.nn.relu(tf.matmul(tf_test_dataset, layer1_weights) + layer1_biases)\n",
    "    last_hidden_layer_test_prediction = tf.nn.relu( \\\n",
    "        tf.matmul(first_hidden_layer_test_prediction, layer2_weights) + layer2_biases)\n",
    "    test_prediction = tf.nn.softmax( \\\n",
    "        tf.matmul(last_hidden_layer_test_prediction, last_layer_weights) + last_layer_biases)\n",
    "\n",
    "    \n",
    "print('Tensorflow Graph created')\n",
    "\n",
    "num_steps = 3001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, tf_l2_feature: 1e-3}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "            print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "            print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "            valid_prediction.eval(), valid_labels))\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Tunning the L2 Regularization constant')\n",
    "\n",
    "l2_constant_values = [pow(10, i) for i in np.arange(-4, -2, 0.1)]\n",
    "accuracy_values = []\n",
    "max_accuracy, best_l2_constant = 0, 0\n",
    "\n",
    "for l2_constant in l2_constant_values:\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        tf.global_variables_initializer().run()\n",
    "        for step in range(num_steps):\n",
    "            # Pick an offset within the training data, which has been randomized.\n",
    "            # Note: we could use better randomization across epochs.\n",
    "            offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "            # Generate a minibatch.\n",
    "            batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "            batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "            # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "            # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "            # and the value is the numpy array to feed to it.\n",
    "            feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, tf_l2_feature: l2_constant}\n",
    "            _, l, predictions = session.run(\n",
    "              [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        test_accuracy = accuracy(test_prediction.eval(), test_labels)\n",
    "        if test_accuracy == max(max_accuracy, test_accuracy):\n",
    "            max_accuracy = test_accuracy\n",
    "            best_l2_constant = l2_constant\n",
    "        accuracy_values.append(test_accuracy)\n",
    "    print('Accuracy of %.2f%% for L2 parameter constant of %f' % (accuracy_values[-1], l2_constant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Plot the L2 Regularization loss for our Test')\n",
    "plt.semilogx(l2_constant_values, accuracy_values)\n",
    "plt.grid(True)\n",
    "plt.title('Accuracy against L2 regularization (Multi Layer Neural Network)')\n",
    "plt.show()\n",
    "print('Maximum accuracy is %.2f%% with L2 Regularization constant of %f' % (max_accuracy, best_l2_constant))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "3_regularization.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
